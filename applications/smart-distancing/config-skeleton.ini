[App]
; The InferenceMode determines the mode of application which can be set to:
; "EVAL" : Will read test images from [Evaluation](ImagesPath) and export the results of inference at [Evaluation](ResultDir)
; "INFERENCE" : Will read the video file as input from [App](VideoPath)
InferenceMode: INFERECE
VideoPath: /repo/applications/smart-distancing/data/TownCentreXVID.avi
Host: 0.0.0.0
Port: 8000
Resolution: 640,480

[Evaluation]
; The directory contains jpg or jpeg test images for evaluating the model
ImagesPath: /repo/applications/smart-distancing/data/test_images
; The path of exporting the detections result
ResultDir: /repo/applications/smart-distancing/eval/detections_results

[Detector]
; Supported devices: Jetson , EdgeTPU, Dummy
Device: EdgeTPU
; Detector's Name can be either "mobilenet_ssd_v2", "pedestrian_ssdlite_mobilenet_v2" or "pedestrian_ssd_mobilenet_v2"
; the first one is trained on COCO dataset and next two are trained on Oxford Town Center dataset to detect pedestrians
Name: pedestrian_ssdlite_mobilenet_v2
; ImageSize should be 3 numbers seperated by commas, no spaces: 300,300,3
ImageSize: 300,300,3
ModelPath: 
ClassID: 0
MinScore: 0.25

[PostProcessor]
MaxTrackFrame: 5
NMSThreshold: 0.98
; distance threshold for smart distancing in (cm)
DistThreshold: 150
; ditance mesurement method, CenterPointsDistance: compare center of pedestrian boxes together, FourCornerPointsDistance: compare four corresponding points of pedestrian boxes and get the minimum of them.
DistMethod: CenterPointsDistance

[Logger]
Name: csv_logger
TimeInterval: 2
LogDirectory: /repo/applications/smart-distancing/ui/static/data


